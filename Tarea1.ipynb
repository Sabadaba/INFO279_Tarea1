{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4bedd9f-4c2f-42f5-9921-312791fb12fa",
   "metadata": {},
   "source": [
    "**Desafío 1** : Construir un modelo de inteligencia artificial capaz de clasificar noticias de prensa según su categoría temática principal. \n",
    "\n",
    "category: sociedad, salud, politica, medioambiente, internacional, entretenimiento, economia, deportes, cultura, cienciatecnologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58cee250-0e62-4118-8afb-87ff1cd8fd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Presentan la Estrategia Regional de Ciencia, T...</td>\n",
       "      <td>En el Distrito de Innovación V21 en Viña del ...</td>\n",
       "      <td>cienciatecnologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ciencia, tecnología, conocimiento e innovación...</td>\n",
       "      <td>miércoles, 14 junio, 2023 a las 21:29 Editor A...</td>\n",
       "      <td>cienciatecnologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Región de Coquimbo contará con el primer parqu...</td>\n",
       "      <td>El Polo Científico y Tecnológico de la Univers...</td>\n",
       "      <td>cienciatecnologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armada invita a investigadores a realizar cien...</td>\n",
       "      <td>Fortalecer el sistema de Ciencia, Tecnología, ...</td>\n",
       "      <td>cienciatecnologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Silvia Díaz es designada para dirigir el Conse...</td>\n",
       "      <td>El Presidente de la República, Gabriel Boric, ...</td>\n",
       "      <td>cienciatecnologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Día del Niño 2023 en Chile: ¿cuánto falta?</td>\n",
       "      <td>TENDENCIAS.- En el mes de agosto en Chile se s...</td>\n",
       "      <td>sociedad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>[OPINION] Rompiendo el micromachismo cultural ...</td>\n",
       "      <td>El reciente caso de apología a la violencia de...</td>\n",
       "      <td>sociedad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>135 años al servicio de la educación de Osorno...</td>\n",
       "      <td>Fundado con el nombre de Liceo de Hombres de O...</td>\n",
       "      <td>sociedad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Presidente Boric promulga Ley TEA</td>\n",
       "      <td>La ley establece la inclusión, atención integr...</td>\n",
       "      <td>sociedad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Municipalidad de Paillaco informó a empresario...</td>\n",
       "      <td>Cerca de 33 representantes de empresas partici...</td>\n",
       "      <td>sociedad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Presentan la Estrategia Regional de Ciencia, T...   \n",
       "1     Ciencia, tecnología, conocimiento e innovación...   \n",
       "2     Región de Coquimbo contará con el primer parqu...   \n",
       "3     Armada invita a investigadores a realizar cien...   \n",
       "4     Silvia Díaz es designada para dirigir el Conse...   \n",
       "...                                                 ...   \n",
       "1995         Día del Niño 2023 en Chile: ¿cuánto falta?   \n",
       "1996  [OPINION] Rompiendo el micromachismo cultural ...   \n",
       "1997  135 años al servicio de la educación de Osorno...   \n",
       "1998                  Presidente Boric promulga Ley TEA   \n",
       "1999  Municipalidad de Paillaco informó a empresario...   \n",
       "\n",
       "                                                   text             target  \n",
       "0      En el Distrito de Innovación V21 en Viña del ...  cienciatecnologia  \n",
       "1     miércoles, 14 junio, 2023 a las 21:29 Editor A...  cienciatecnologia  \n",
       "2     El Polo Científico y Tecnológico de la Univers...  cienciatecnologia  \n",
       "3     Fortalecer el sistema de Ciencia, Tecnología, ...  cienciatecnologia  \n",
       "4     El Presidente de la República, Gabriel Boric, ...  cienciatecnologia  \n",
       "...                                                 ...                ...  \n",
       "1995  TENDENCIAS.- En el mes de agosto en Chile se s...           sociedad  \n",
       "1996  El reciente caso de apología a la violencia de...           sociedad  \n",
       "1997  Fundado con el nombre de Liceo de Hombres de O...           sociedad  \n",
       "1998  La ley establece la inclusión, atención integr...           sociedad  \n",
       "1999  Cerca de 33 representantes de empresas partici...           sociedad  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lee el archivo CSV en un DataFrame de pandas\n",
    "#df = pd.read_csv(\"train_data.csv\",thousands=',')\n",
    "df = pd.read_csv(\"final_output.csv\",thousands=',')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea6bc65-5e4f-4ec9-a588-286701e7db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['clase'] = df['clase'].replace(['ciencia', 'tecnologia'], 'cienciatecnologia')\n",
    "#df['clase'] = df['clase'].replace('medio_ambiente', 'medioambiente')\n",
    "#df['clase'] = df['clase'].replace('accidentes', 'sociedad')\n",
    "#df['clase'] = df['clase'].replace('educacion', 'cultura')\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458df80c-fb8a-4f8f-9a9e-65e66c1dd9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sociedad', 'cultura', 'medioambiente', 'entretenimiento', 'salud',\n",
       "       'cienciatecnologia', 'internacional', 'deportes', 'economia',\n",
       "       'politica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Obtén 1000 filas aleatorias del DataFrame\n",
    "random_rows = df.sample(n=1000, random_state=42)\n",
    "\n",
    "# Encuentra las clases únicas en la columna \"clase\"\n",
    "unique_classes = random_rows[\"target\"].unique()\n",
    "\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1055c72e-684d-443f-8917-75d9448936ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crea la lista de tuplas con las etiquetas de clases\n",
    "data_list = []\n",
    "for _, row in random_rows.iterrows():\n",
    "    title = row[\"title\"]\n",
    "    clase = row[\"target\"]\n",
    "    cats = {cls: 1 if cls == clase else 0 for cls in unique_classes}\n",
    "    data_list.append((title, {\"cats\": cats}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff6ac288-9cad-4e1a-a9b9-40b2313db0fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ejecutar dos veces\n",
    "import spacy\n",
    "import random\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch\n",
    "\n",
    "from spacy.pipeline.tok2vec import DEFAULT_TOK2VEC_MODEL\n",
    "\n",
    "# Datos de entrenamiento\n",
    "TRAIN_DATA = data_list\n",
    "\n",
    "# Inicializar spaCy con el modelo de lenguaje es_core_news_sm\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "train_examples = []\n",
    "\n",
    "for example in TRAIN_DATA:\n",
    "    train_examples.append(Example.from_dict(nlp.make_doc(example[0]), example[1]))\n",
    "\n",
    "def get_examples():\n",
    "    return train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e45498d-9793-4503-8e5d-c633e0d0f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "            \"@architectures\": \"spacy.TextCatCNN.v2\",\n",
    "            \"exclusive_classes\": True,\n",
    "            \"tok2vec\": DEFAULT_TOK2VEC_MODEL,\n",
    "        }\n",
    "\n",
    "# Crear un componente TextCategorizer con un modelo CNN\n",
    "textcat = nlp.add_pipe(\"textcat\", config={\"model\": model})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf60fa19-7e01-46ed-ad2c-e76d64ed41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcat.initialize(get_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c89514cf-72df-40f0-ac09-262b3b468822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 42.04787262529135}\n",
      "{'textcat': 39.407292203977704}\n",
      "{'textcat': 34.1174188349396}\n",
      "{'textcat': 26.65628725447459}\n",
      "{'textcat': 19.59091913700999}\n",
      "{'textcat': 14.185280643296622}\n",
      "{'textcat': 10.900772118390027}\n",
      "{'textcat': 6.88285094215385}\n",
      "{'textcat': 6.937038271598017}\n",
      "{'textcat': 5.522471897606755}\n",
      "{'textcat': 3.9843649150106972}\n",
      "{'textcat': 3.6106549937896335}\n",
      "{'textcat': 3.351309838361964}\n",
      "{'textcat': 2.4135422545970315}\n",
      "{'textcat': 2.789866827136741}\n",
      "{'textcat': 2.753406449486765}\n",
      "{'textcat': 2.6314961797474847}\n",
      "{'textcat': 1.9298980198088016}\n",
      "{'textcat': 2.2654393788621503}\n",
      "{'textcat': 2.9632438219715516}\n",
      "{'textcat': 2.517671748243197}\n",
      "{'textcat': 0.9807545487040265}\n",
      "{'textcat': 1.1602422296532973}\n",
      "{'textcat': 1.7863832779078959}\n",
      "{'textcat': 1.5120839585148365}\n",
      "{'textcat': 0.983756489226982}\n",
      "{'textcat': 1.8703214652866966}\n",
      "{'textcat': 1.3476757326938766}\n",
      "{'textcat': 1.447258636445983}\n",
      "{'textcat': 1.3156574518309874}\n",
      "{'textcat': 1.4332365998508507}\n",
      "{'textcat': 1.539878447446133}\n",
      "{'textcat': 0.7532943572583083}\n",
      "{'textcat': 0.6739435864131695}\n",
      "{'textcat': 0.9577978761360507}\n",
      "{'textcat': 0.8859071028517742}\n",
      "{'textcat': 1.0007891438723657}\n",
      "{'textcat': 1.3194168722085906}\n",
      "{'textcat': 0.8864432492278685}\n",
      "{'textcat': 0.7310553571079395}\n",
      "{'textcat': 0.9801379748069967}\n",
      "{'textcat': 0.8868225596429832}\n",
      "{'textcat': 0.7243047426667507}\n",
      "{'textcat': 0.542989019336806}\n",
      "{'textcat': 0.6686951633836768}\n",
      "{'textcat': 0.7295667103140971}\n",
      "{'textcat': 0.924346569773798}\n",
      "{'textcat': 0.5880020568545298}\n",
      "{'textcat': 0.8390538563389456}\n",
      "{'textcat': 0.6187077584945646}\n",
      "{'textcat': 0.7142986720189464}\n",
      "{'textcat': 0.2895619793051226}\n",
      "{'textcat': 0.6114038097224902}\n",
      "{'textcat': 0.3819806831930702}\n",
      "{'textcat': 0.333779406619329}\n",
      "{'textcat': 0.8563970053844472}\n",
      "{'textcat': 0.4827750020218041}\n",
      "{'textcat': 1.0151927658413422}\n",
      "{'textcat': 0.47643754721086967}\n",
      "{'textcat': 0.3489454189099196}\n",
      "{'textcat': 0.40949822809870745}\n",
      "{'textcat': 0.4728609559509712}\n",
      "{'textcat': 0.4148830685642535}\n",
      "{'textcat': 0.6007544731150524}\n",
      "{'textcat': 0.7565099345438717}\n",
      "{'textcat': 0.4553718726519633}\n",
      "{'textcat': 0.41887046073411405}\n",
      "{'textcat': 0.5317813321539203}\n",
      "{'textcat': 0.6822522900756623}\n",
      "{'textcat': 0.48549359838488537}\n",
      "{'textcat': 0.3310807401906033}\n",
      "{'textcat': 0.20119363971629475}\n",
      "{'textcat': 0.3584212457303365}\n",
      "{'textcat': 0.33807462090337537}\n",
      "{'textcat': 0.314518027027467}\n",
      "{'textcat': 1.1034568761588675}\n",
      "{'textcat': 0.23373545079150104}\n",
      "{'textcat': 0.28987795990423}\n",
      "{'textcat': 0.2190806463458565}\n",
      "{'textcat': 0.19076340417328516}\n",
      "{'textcat': 0.25914782971198724}\n",
      "{'textcat': 0.26833676494872977}\n",
      "{'textcat': 0.537737184629783}\n",
      "{'textcat': 0.3675311816079015}\n",
      "{'textcat': 0.14984941580994005}\n",
      "{'textcat': 0.3702943504063701}\n",
      "{'textcat': 0.16858889165294647}\n",
      "{'textcat': 0.5247323769340492}\n",
      "{'textcat': 0.4016648307616885}\n",
      "{'textcat': 0.337894483460244}\n",
      "{'textcat': 0.33043459707363776}\n",
      "{'textcat': 0.5261968226430711}\n",
      "{'textcat': 0.6819851893805596}\n",
      "{'textcat': 0.24912684440837773}\n",
      "{'textcat': 0.42311369717692904}\n",
      "{'textcat': 0.3202560016293403}\n",
      "{'textcat': 0.15688025884825185}\n",
      "{'textcat': 0.36129071013609054}\n",
      "{'textcat': 0.14911370879382738}\n",
      "{'textcat': 0.34280951134669985}\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import compounding\n",
    "\n",
    "# Entrenar el modelo\n",
    "with nlp.select_pipes(enable=\"textcat\"):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for epoch in range(100):\n",
    "        losses = {}\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        # Dividir los datos en lotes y actualizar el modelo\n",
    "        for batch in minibatch(TRAIN_DATA, size=compounding(2.0, 32.0, 1.001)):\n",
    "            texts, annotations = zip(*batch)\n",
    "            example = []\n",
    "            # Actualizar el modelo con iteraciones\n",
    "            for i in range(len(texts)):\n",
    "                doc = nlp.make_doc(texts[i])\n",
    "                example.append(Example.from_dict(doc, annotations[i]))\n",
    "            nlp.update(example, drop=0.5, losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3802fd6e-dde8-4200-9f20-c54f4f8f42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado en disco\n",
    "nlp.to_disk(\"modeloTarea1_1_CNNv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966bd91e-90ae-47cb-98c3-16fe9afb0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo entrenado\n",
    "nlp_loaded = spacy.load(\"modeloTarea1_1_CNNv2\")#modelo_clasificador_noticias\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d8eba-86d0-4091-b341-16e750b5bd0f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "***Desafío 2***: Geolocalizar eventos en noticias\n",
    "\n",
    "Utilizando técnicas de tratamiento automático del lenguaje, el objetivo del desafío es estructurar la información de una noticia de la manera siguiente:\n",
    "\n",
    "event: principal evento descrito en la noticia\n",
    "category: categoria temática del evento\n",
    "address: dirección dónde occurió el evento en formato: calle número, comuna, país\n",
    "latitud: latitud del evento\n",
    "longitud: longitud del evento\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Resultado: El formato del archivo CSV output que entregar contiene las columnas siguientes: id_news, event, category, address, latitud, longitud\n",
    "\n",
    "\n",
    "Evaluación del desafío: Se evaluará su método en base a 100 noticias etiquetadas con las métricas siguientes:\n",
    "Category: Precision y Recall\n",
    "Longitud y Latitud: Exactitud (con una margen de error de 100 metros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "308770a4-dbad-408a-a853-0687230ff87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebaa\\INFO\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"Sophia\")\n",
    "\n",
    "modelAdd=\"mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelAdd)\n",
    "\n",
    "modelAdd = AutoModelForQuestionAnswering.from_pretrained(modelAdd)\n",
    "\n",
    "nlp2 = pipeline(\"question-answering\", model=modelAdd, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6c33b82-38de-4799-8e7d-974d24a8ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('dataset_agosto2024.csv',thousands=',')\n",
    "df2 = df2.dropna()\n",
    "df2 = df2[df2['text'] != '(empty)']\n",
    "\n",
    "questions = [\n",
    "    \"¿Cuál es el evento principal descrito en el texto?\",\n",
    "    \"¿En que país tuvo lugar el hecho?\",\n",
    "    \"¿En que Comuna ocurrio el hecho?\",\n",
    "    \"¿En que calle ocurrio el hecho?\"\n",
    "]\n",
    "\n",
    "df2['event'] = ''\n",
    "df2['category'] = ''\n",
    "df2['address'] = ''\n",
    "df2['latitud'] = ''\n",
    "df2['longitud'] = ''\n",
    "\n",
    "df2 = df2.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71f18126-81b4-48ae-82ec-a1f00ead9713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Error con la locacion, colocando coordenadas predetemiandas\n",
      "Creado archivo .csv\n"
     ]
    }
   ],
   "source": [
    "for index, row in df2.iterrows():  \n",
    "    Answer = []\n",
    "    for question in questions: \n",
    "        result = nlp2(question=question, tokenizer=tokenizer, model=modelAdd, context=row['text'])\n",
    "        Answer.append(result['answer'])\n",
    "        #print(question)\n",
    "        #print(result['answer'])\n",
    "    \n",
    "    #Event\n",
    "    df2.at[index,'event'] = Answer[0]\n",
    "    \n",
    "    #Address\n",
    "    lugar = Answer[2] +\", \"+ Answer[1]\n",
    "    df2.at[index,'address'] = lugar\n",
    "    \n",
    "    #Latitude, Longitude\n",
    "    try:\n",
    "        location = geolocator.geocode(lugar)\n",
    "        #print(location.address)\n",
    "        #print((location.latitude, location.longitude))\n",
    "        df2.at[index,'latitud'] = location.latitude\n",
    "        df2.at[index,'longitud'] = location.longitude\n",
    "        #print(row['address'])\n",
    "    except Exception as e:\n",
    "        print(\"Error con la locacion, colocando coordenadas predetemiandas\")\n",
    "        df2.at[index,'latitud'] = 0.0\n",
    "        df2.at[index,'longitud'] = 0.0        \n",
    "    \n",
    "    #Categoria\n",
    "    doc = nlp_loaded(row['title'])\n",
    "    #print(\"Categorías predichas:\")\n",
    "    maxscore = 0.0\n",
    "    maxlabel = ''\n",
    "    for label, score in doc.cats.items():\n",
    "        if (score > maxscore):\n",
    "            maxscore = score\n",
    "            maxlabel = label\n",
    "    #print(f\"{maxlabel}: {maxscore:.4f}\")\n",
    "    df2.at[index,'category'] = maxlabel\n",
    "\n",
    "output_columns = ['id_news', 'event', 'category', 'address', 'latitud', 'longitud']\n",
    "df2[output_columns].to_csv('desafio2_output.csv', index=False)\n",
    "print(\"Creado archivo .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0eff0-cb3b-4fb0-a5e5-712071fd74d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
